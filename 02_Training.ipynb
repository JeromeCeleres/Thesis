{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from multiprocessing import cpu_count, Pool #for multiprocessing data\n",
    "cores = cpu_count()\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument #for doc2vec modelling\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bonding, grief, family, urban, poor, communit...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[general, santos, city, number, drug, suspect,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[brig, gen, debold, sinas, director, national,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[politics, eyed, police, say, politics, may, b...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[general, santos, city, president, rodrigo, du...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized label\n",
       "0  [bonding, grief, family, urban, poor, communit...  ejks\n",
       "1  [general, santos, city, number, drug, suspect,...  ejks\n",
       "2  [brig, gen, debold, sinas, director, national,...  ejks\n",
       "3  [politics, eyed, police, say, politics, may, b...  ejks\n",
       "4  [general, santos, city, president, rodrigo, du...  ejks"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./Cleaned/ejks_cleaned.pkl')[['lemmatized', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[eastern, samar, gone, really, dont, know, sta...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[market, stall, product, damaged, washed, debr...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[knew, super, typhoon, strength, really, took,...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[compared, wind, rain, strong, staed, whistle,...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[thought, prepared, used, typhoon, know, feel,...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized     label\n",
       "0  [eastern, samar, gone, really, dont, know, sta...  disaster\n",
       "1  [market, stall, product, damaged, washed, debr...  disaster\n",
       "2  [knew, super, typhoon, strength, really, took,...  disaster\n",
       "3  [compared, wind, rain, strong, staed, whistle,...  disaster\n",
       "4  [thought, prepared, used, typhoon, know, feel,...  disaster"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_pickle('./Cleaned/disaster_cleaned.pkl')[['lemmatized', 'label']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = df.append(df1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ejks        371\n",
       "disaster    122\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.to_csv('main.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = main[main.label == 'ejks']\n",
    "df_minority = main[main.label == 'disaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=371,    # to match majority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bonding, grief, family, urban, poor, communit...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[general, santos, city, number, drug, suspect,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[brig, gen, debold, sinas, director, national,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[politics, eyed, police, say, politics, may, b...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[general, santos, city, president, rodrigo, du...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>[nine, nearly, ten, new, zealand, struck, tida...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>[grew, poor, gulf, lived, lot, hurricane, wors...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>[time, working, new, zealand, banker, associat...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>[grew, poor, gulf, lived, lot, hurricane, wors...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>[nothing, green, left, almost, tree, plant, da...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lemmatized     label\n",
       "0    [bonding, grief, family, urban, poor, communit...      ejks\n",
       "1    [general, santos, city, number, drug, suspect,...      ejks\n",
       "2    [brig, gen, debold, sinas, director, national,...      ejks\n",
       "3    [politics, eyed, police, say, politics, may, b...      ejks\n",
       "4    [general, santos, city, president, rodrigo, du...      ejks\n",
       "..                                                 ...       ...\n",
       "453  [nine, nearly, ten, new, zealand, struck, tida...  disaster\n",
       "474  [grew, poor, gulf, lived, lot, hurricane, wors...  disaster\n",
       "461  [time, working, new, zealand, banker, associat...  disaster\n",
       "474  [grew, poor, gulf, lived, lot, hurricane, wors...  disaster\n",
       "406  [nothing, green, left, almost, tree, plant, da...  disaster\n",
       "\n",
       "[742 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.to_csv('main_upsampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bonding, grief, family, urban, poor, communit...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[general, santos, city, number, drug, suspect,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[brig, gen, debold, sinas, director, national,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[politics, eyed, police, say, politics, may, b...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[general, santos, city, president, rodrigo, du...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>[nine, nearly, ten, new, zealand, struck, tida...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>[grew, poor, gulf, lived, lot, hurricane, wors...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>[time, working, new, zealand, banker, associat...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>[grew, poor, gulf, lived, lot, hurricane, wors...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>[nothing, green, left, almost, tree, plant, da...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lemmatized     label\n",
       "0    [bonding, grief, family, urban, poor, communit...      ejks\n",
       "1    [general, santos, city, number, drug, suspect,...      ejks\n",
       "2    [brig, gen, debold, sinas, director, national,...      ejks\n",
       "3    [politics, eyed, police, say, politics, may, b...      ejks\n",
       "4    [general, santos, city, president, rodrigo, du...      ejks\n",
       "..                                                 ...       ...\n",
       "453  [nine, nearly, ten, new, zealand, struck, tida...  disaster\n",
       "474  [grew, poor, gulf, lived, lot, hurricane, wors...  disaster\n",
       "461  [time, working, new, zealand, banker, associat...  disaster\n",
       "474  [grew, poor, gulf, lived, lot, hurricane, wors...  disaster\n",
       "406  [nothing, green, left, almost, tree, plant, da...  disaster\n",
       "\n",
       "[742 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging docs...\n",
      "Docs tagged.\n",
      "Training start.\n",
      "Initializing Model...\n",
      "Model Initalized. Training...\n",
      "Training complete.\n",
      "Saving model...\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "print('Tagging docs...')\n",
    "docs = [x for x in main['lemmatized'].values]\n",
    "# docs = [x for x in main_df['content_clean'].values]\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs)]\n",
    "print('Docs tagged.')\n",
    "# tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "print('Training start.')\n",
    "# epoch_logger = EpochLogger()\n",
    "epochs = 50\n",
    "vec_size = 50\n",
    "alpha = 0.025\n",
    "\n",
    "print('Initializing Model...')\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=2,\n",
    "                workers = cores,\n",
    "                dm = 1, epochs = epochs)\n",
    "#                 callbacks=[epoch_logger])\n",
    "                \n",
    "\n",
    "print('Model Initalized. Training...')\n",
    "model.build_vocab(documents = documents, progress_per=1)\n",
    "print('Training complete.')\n",
    "\n",
    "print('Saving model...')\n",
    "model.save(\"models/doc2vec.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 22,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [model.docvecs[i] for i in range(len(main))]\n",
    "main['vector_d2v'] = vectors"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 23,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "      <th>vector_d2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bonding, grief, family, urban, poor, communit...</td>\n",
       "      <td>ejks</td>\n",
<<<<<<< HEAD
       "      <td>[0.0017050115, 0.0018064021, -0.0016239737, -0...</td>\n",
=======
       "      <td>[0.003405938, -0.005817423, 0.0006343011, -0.0...</td>\n",
>>>>>>> refs/remotes/origin/master
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[general, santos, city, number, drug, suspect,...</td>\n",
       "      <td>ejks</td>\n",
<<<<<<< HEAD
       "      <td>[-0.0057221856, 0.0062061665, 0.0041595153, -0...</td>\n",
=======
       "      <td>[0.0072190813, 0.0015787937, 0.008548453, -0.0...</td>\n",
>>>>>>> refs/remotes/origin/master
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[brig, gen, debold, sinas, director, national,...</td>\n",
       "      <td>ejks</td>\n",
<<<<<<< HEAD
       "      <td>[0.008484206, 0.0051286668, 0.009918391, 0.003...</td>\n",
=======
       "      <td>[0.0016313813, -0.008899071, -0.0010293353, 0....</td>\n",
>>>>>>> refs/remotes/origin/master
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[politics, eyed, police, say, politics, may, b...</td>\n",
       "      <td>ejks</td>\n",
<<<<<<< HEAD
       "      <td>[0.0011358617, 0.0011977549, 0.001955342, 0.00...</td>\n",
=======
       "      <td>[-0.0076317787, -0.0007446008, -0.0072954814, ...</td>\n",
>>>>>>> refs/remotes/origin/master
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[general, santos, city, president, rodrigo, du...</td>\n",
       "      <td>ejks</td>\n",
<<<<<<< HEAD
       "      <td>[-0.0070313467, -0.0006196055, -0.0066429903, ...</td>\n",
=======
       "      <td>[0.0026413533, 0.0018884231, -0.0076236646, 0....</td>\n",
>>>>>>> refs/remotes/origin/master
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized label  \\\n",
       "0  [bonding, grief, family, urban, poor, communit...  ejks   \n",
       "1  [general, santos, city, number, drug, suspect,...  ejks   \n",
       "2  [brig, gen, debold, sinas, director, national,...  ejks   \n",
       "3  [politics, eyed, police, say, politics, may, b...  ejks   \n",
       "4  [general, santos, city, president, rodrigo, du...  ejks   \n",
       "\n",
       "                                          vector_d2v  \n",
<<<<<<< HEAD
       "0  [0.0017050115, 0.0018064021, -0.0016239737, -0...  \n",
       "1  [-0.0057221856, 0.0062061665, 0.0041595153, -0...  \n",
       "2  [0.008484206, 0.0051286668, 0.009918391, 0.003...  \n",
       "3  [0.0011358617, 0.0011977549, 0.001955342, 0.00...  \n",
       "4  [-0.0070313467, -0.0006196055, -0.0066429903, ...  "
      ]
     },
     "execution_count": 17,
=======
       "0  [0.003405938, -0.005817423, 0.0006343011, -0.0...  \n",
       "1  [0.0072190813, 0.0015787937, 0.008548453, -0.0...  \n",
       "2  [0.0016313813, -0.008899071, -0.0010293353, 0....  \n",
       "3  [-0.0076317787, -0.0007446008, -0.0072954814, ...  \n",
       "4  [0.0026413533, 0.0018884231, -0.0076236646, 0....  "
      ]
     },
     "execution_count": 23,
>>>>>>> refs/remotes/origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 36,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 37,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(col):\n",
    "    li = []\n",
    "    for i in col:\n",
    "        li.append(i.reshape(1, -1))\n",
    "    return np.concatenate(li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 38,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = main['vector_d2v']\n",
    "X = get_X(X_sub)\n",
    "y = main['label']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 39,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) SVM"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 40,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 22,
=======
     "execution_count": 40,
>>>>>>> refs/remotes/origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 41,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.decision_function(X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.88316401e-01, -1.42890557e-02, -1.13607920e-01, -3.65141671e-01,\n",
       "        7.08589211e-01, -3.32816391e-01, -3.06122867e-01,  1.02250368e-01,\n",
       "       -4.69372748e-01, -3.12168617e-01, -2.25502267e-01, -3.01421271e-01,\n",
       "       -5.64436162e-01, -5.89851309e-01, -3.37144997e-01,  1.91286146e-01,\n",
       "        1.74477213e-01, -3.94890653e-01,  2.56684975e-01, -7.29413491e-01,\n",
       "       -3.01859084e-01,  1.89937195e-01,  6.94133351e-01, -2.43882859e-02,\n",
       "        8.95564143e-01,  1.70652664e-01,  3.75364801e-02,  3.05392291e-01,\n",
       "       -4.65096927e-02, -5.46798480e-01,  2.20955466e-01, -2.85077233e-02,\n",
       "        4.94464764e-01,  4.61320492e-01, -1.16375268e+00, -4.66699602e-01,\n",
       "       -1.38214049e-01,  7.97793103e-02, -4.26781076e-01, -6.06957763e-01,\n",
       "        5.29413855e-02,  2.86858746e-01,  6.58176780e-01, -1.69865412e-01,\n",
       "       -1.27218027e-01,  7.69962765e-01,  2.71443098e-01,  1.67077601e-01,\n",
       "        5.75049243e-01,  1.24046640e+00,  2.15830115e-01,  3.83229514e-01,\n",
       "        8.04559433e-02, -4.27202467e-01,  1.92534730e-01, -3.21817403e-01,\n",
       "        2.22975425e-01, -1.32972706e-01,  3.04551351e-01, -3.65763320e-01,\n",
       "       -1.14338857e-01,  3.49626458e-01, -4.25726096e-01, -6.42882473e-01,\n",
       "       -7.39774831e-01, -1.41220481e-01, -5.45991944e-01, -1.19222854e-01,\n",
       "        2.75821170e-01,  2.98500074e-01, -3.07591751e-01,  4.90200015e-01,\n",
       "        1.33908412e-02,  6.41471601e-01,  4.89311831e-01,  7.67675464e-01,\n",
       "        4.55333996e-01,  1.03870136e+00,  3.64359249e-01,  2.31521491e-01,\n",
       "       -2.32609429e-02, -1.76189159e-01,  7.42245884e-01, -1.97126397e-01,\n",
       "       -6.55321546e-01,  3.19044186e-01, -1.04113151e+00, -7.01999964e-01,\n",
       "       -6.85601750e-01,  6.66536210e-01,  2.91623582e-01,  5.62197992e-02,\n",
       "       -5.89733594e-02, -2.61191167e-01, -4.99102627e-01, -4.06751709e-01,\n",
       "       -4.51845841e-01, -2.22572749e-01, -7.16958147e-01, -1.50073956e-01,\n",
       "       -3.41822077e-01,  6.37066070e-02, -1.87750182e-01,  1.82706060e-01,\n",
       "       -1.66231461e-01, -2.07353534e-01, -2.72169291e-01,  2.57557669e-01,\n",
       "        1.57061709e-01, -9.24902813e-02,  3.63009145e-01, -1.30094383e+00,\n",
       "       -1.25852656e-01,  9.38318306e-02,  7.28356194e-01,  7.27412182e-02,\n",
       "       -3.23709753e-01, -2.09770904e-01,  3.82665189e-01, -2.26504843e-01,\n",
       "        1.99816451e-01,  2.49545328e-01,  4.69352412e-01, -3.04791094e-01,\n",
       "        3.60851195e-01,  1.69397303e-02,  4.93769956e-02,  2.96092649e-01,\n",
       "       -3.74232267e-01, -1.00333914e-03, -4.61632827e-02, -3.17509809e-01,\n",
       "        8.47591098e-01,  7.13336389e-01,  1.52775622e-01,  7.39701663e-01,\n",
       "       -1.93563319e-02, -4.49588024e-02, -1.62322429e-02,  5.01982269e-02,\n",
       "       -2.33094603e-02,  4.14906782e-01,  1.11624796e-01, -4.75297725e-01,\n",
       "        2.35348807e-01,  1.84557534e-01, -5.07403784e-01, -1.64907997e-01,\n",
       "       -3.47121413e-02])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
=======
   "execution_count": 42,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
<<<<<<< HEAD
      "    disaster       0.52      0.49      0.51        77\n",
      "        ejks       0.49      0.51      0.50        72\n",
      "\n",
      "    accuracy                           0.50       149\n",
      "   macro avg       0.50      0.50      0.50       149\n",
      "weighted avg       0.50      0.50      0.50       149\n",
=======
      "    disaster       0.49      0.52      0.51        69\n",
      "        ejks       0.57      0.54      0.55        80\n",
      "\n",
      "    accuracy                           0.53       149\n",
      "   macro avg       0.53      0.53      0.53       149\n",
      "weighted avg       0.53      0.53      0.53       149\n",
>>>>>>> refs/remotes/origin/master
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_svm, y_test))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is invalid. Set it to a label in y_true.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8a1147ed53d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maverage_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             raise ValueError(\"pos_label=%r is invalid. Set it to a label in \"\n\u001b[0;32m--> 211\u001b[0;31m                              \"y_true.\" % pos_label)\n\u001b[0m\u001b[1;32m    212\u001b[0m     average_precision = partial(_binary_uninterpolated_average_precision,\n\u001b[1;32m    213\u001b[0m                                 pos_label=pos_label)\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=1 is invalid. Set it to a label in y_true."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
=======
   "execution_count": 43,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy: 0.5033557046979866\n"
=======
      "Accuracy: 0.5302013422818792\n"
>>>>>>> refs/remotes/origin/master
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Random Forest"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 44,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=50, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 30,
=======
     "execution_count": 44,
>>>>>>> refs/remotes/origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 45,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 46,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
<<<<<<< HEAD
      "    disaster       0.58      0.51      0.54        83\n",
      "        ejks       0.46      0.53      0.49        66\n",
      "\n",
      "    accuracy                           0.52       149\n",
      "   macro avg       0.52      0.52      0.52       149\n",
      "weighted avg       0.52      0.52      0.52       149\n",
=======
      "    disaster       0.55      0.52      0.53        77\n",
      "        ejks       0.51      0.54      0.53        72\n",
      "\n",
      "    accuracy                           0.53       149\n",
      "   macro avg       0.53      0.53      0.53       149\n",
      "weighted avg       0.53      0.53      0.53       149\n",
>>>>>>> refs/remotes/origin/master
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 47,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy: 0.5167785234899329\n"
=======
      "Accuracy: 0.5302013422818792\n"
>>>>>>> refs/remotes/origin/master
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 48,
>>>>>>> refs/remotes/origin/master
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/rf_model.pkl']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 34,
=======
     "execution_count": 48,
>>>>>>> refs/remotes/origin/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf, 'models/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf, open('models/rf_model2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> refs/remotes/origin/master
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
