{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from multiprocessing import cpu_count, Pool #for multiprocessing data\n",
    "cores = cpu_count()\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument #for doc2vec modelling\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('content_2.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.decision_date.apply(lambda x : int(re.findall('^\\d{4}', x)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df['content_clean'] = df['content'].apply(lambda x: re.sub(re.compile('\\.'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('<.*?>'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('\\r?\\n|\\r'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('^.*?\\:'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('(^|\\s).(\\s|$):'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('\\s*[A-Z]+\\s'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('GR\\s|No\\s|January|February|March|April|May|June|July|August|September|October|November|December'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: re.sub(re.compile('[^a-zA-Z -]'), ' ', x))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords.words(\"english\"))]))\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: x.lower())\n",
    "    df['content_clean'] = df['content_clean'].apply(lambda x: x.split())\n",
    "    return df\n",
    "\n",
    "def parallel_df_process(df, func, n_cores=cores):\n",
    "    pool = Pool(n_cores)\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    df_joined = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = parallel_df_process(df, clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'established', 'fact', 'brooks', 'obtained', 'absolute', 'discharge', 'soldier', 'it', 'likewise', 'fact', 'explicitly', 'stated', 'counsel', 'government']\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.content_clean.iloc[0][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "\n",
    "def stem_df(df):\n",
    "    df['stemmed'] = df['content_clean'].apply(lambda x : [porter.stem(word) for word in x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = parallel_df_process(df_cleaned, stem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'establish', 'fact', 'brook', 'obtain', 'absolut', 'discharg', 'soldier', 'it', 'likewis', 'fact', 'explicitli', 'state', 'counsel', 'govern']\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.stemmed.iloc[0][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1900\n",
    "main_df = df_cleaned[(df.year >= year) & (df.label != \"Part I\") & (df.label != \"Part II\") & (df.label != \"Part III\") & (df.label != \"Part IV\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>case_title</th>\n",
       "      <th>gr_no</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>143051.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 507, Novembe...</td>\n",
       "      <td>IN THE MATTER OF THE PETITION OF A. O. BROOKS ...</td>\n",
       "      <td>G.R. No. 507</td>\n",
       "      <td>1901-11-05</td>\n",
       "      <td>Remedial Law</td>\n",
       "      <td>1901</td>\n",
       "      <td>[it, established, fact, brooks, obtained, abso...</td>\n",
       "      <td>[it, establish, fact, brook, obtain, absolut, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>143062.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 448, Septemb...</td>\n",
       "      <td>THE UNITED STATES, COMPLAINANT AND APPELLEE, V...</td>\n",
       "      <td>G.R. No. 448</td>\n",
       "      <td>1901-09-20</td>\n",
       "      <td>Criminal Law</td>\n",
       "      <td>1901</td>\n",
       "      <td>[the, offense, charged, complaint, punishable,...</td>\n",
       "      <td>[the, offens, charg, complaint, punish, penal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>143169.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 448, Septemb...</td>\n",
       "      <td>THE UNITED STATES, COMPLAINANT AND APPELLEE, V...</td>\n",
       "      <td>G.R. No. 448</td>\n",
       "      <td>1902-09-20</td>\n",
       "      <td>Criminal Law</td>\n",
       "      <td>1902</td>\n",
       "      <td>[the, offense, charged, complaint, punishable,...</td>\n",
       "      <td>[the, offens, charg, complaint, punish, penal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>143252.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 911, March 1...</td>\n",
       "      <td>MAXIMO CORTES, PLAINTIFF AND APPELLANT, VS.  J...</td>\n",
       "      <td>G.R. No. 911</td>\n",
       "      <td>1903-03-12</td>\n",
       "      <td>Civil Law</td>\n",
       "      <td>1903</td>\n",
       "      <td>[this, suit, brought, obtain, injunction, acco...</td>\n",
       "      <td>[thi, suit, brought, obtain, injunct, accord, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>143269.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 1011, May 13...</td>\n",
       "      <td>JOSE MACHUCA, PLAINTIFF AND APPELLEE, VS. CHUI...</td>\n",
       "      <td>G.R. No. 1011</td>\n",
       "      <td>1903-05-13</td>\n",
       "      <td>Civil Law</td>\n",
       "      <td>1903</td>\n",
       "      <td>[most, allegations, complaint, admitted, defen...</td>\n",
       "      <td>[most, alleg, complaint, admit, defend, hear, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            content  \\\n",
       "8    143051.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 507, Novembe...   \n",
       "19   143062.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 448, Septemb...   \n",
       "126  143169.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 448, Septemb...   \n",
       "209  143252.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 911, March 1...   \n",
       "226  143269.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 1011, May 13...   \n",
       "\n",
       "                                            case_title          gr_no  \\\n",
       "8    IN THE MATTER OF THE PETITION OF A. O. BROOKS ...   G.R. No. 507   \n",
       "19   THE UNITED STATES, COMPLAINANT AND APPELLEE, V...   G.R. No. 448   \n",
       "126  THE UNITED STATES, COMPLAINANT AND APPELLEE, V...   G.R. No. 448   \n",
       "209  MAXIMO CORTES, PLAINTIFF AND APPELLANT, VS.  J...   G.R. No. 911   \n",
       "226  JOSE MACHUCA, PLAINTIFF AND APPELLEE, VS. CHUI...  G.R. No. 1011   \n",
       "\n",
       "    decision_date         label  year  \\\n",
       "8      1901-11-05  Remedial Law  1901   \n",
       "19     1901-09-20  Criminal Law  1901   \n",
       "126    1902-09-20  Criminal Law  1902   \n",
       "209    1903-03-12     Civil Law  1903   \n",
       "226    1903-05-13     Civil Law  1903   \n",
       "\n",
       "                                         content_clean  \\\n",
       "8    [it, established, fact, brooks, obtained, abso...   \n",
       "19   [the, offense, charged, complaint, punishable,...   \n",
       "126  [the, offense, charged, complaint, punishable,...   \n",
       "209  [this, suit, brought, obtain, injunction, acco...   \n",
       "226  [most, allegations, complaint, admitted, defen...   \n",
       "\n",
       "                                               stemmed  \n",
       "8    [it, establish, fact, brook, obtain, absolut, ...  \n",
       "19   [the, offens, charg, complaint, punish, penal,...  \n",
       "126  [the, offens, charg, complaint, punish, penal,...  \n",
       "209  [thi, suit, brought, obtain, injunct, accord, ...  \n",
       "226  [most, alleg, complaint, admit, defend, hear, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 3582\n"
     ]
    }
   ],
   "source": [
    "print('Length:', main_df.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_pickle(\"main_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging docs...\n",
      "Docs tagged.\n",
      "Training start.\n",
      "Initializing Model...\n",
      "Model Initalized. Training...\n",
      "Training complete.\n",
      "Saving model...\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "print('Tagging docs...')\n",
    "docs = [x for x in main_df['stemmed'].values]\n",
    "# docs = [x for x in main_df['content_clean'].values]\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs)]\n",
    "print('Docs tagged.')\n",
    "# tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "print('Training start.')\n",
    "# epoch_logger = EpochLogger()\n",
    "epochs = 50\n",
    "vec_size = 50\n",
    "alpha = 0.025\n",
    "\n",
    "print('Initializing Model...')\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=2,\n",
    "                workers = cores,\n",
    "                dm = 1, epochs = epochs)\n",
    "#                 callbacks=[epoch_logger])\n",
    "                \n",
    "\n",
    "print('Model Initalized. Training...')\n",
    "model.build_vocab(documents = documents, progress_per=1)\n",
    "print('Training complete.')\n",
    "\n",
    "print('Saving model...')\n",
    "model.save(\"d2vmodel/d2vlegaldocs.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "vectors = [model.docvecs[i] for i in range(len(main_df))]\n",
    "main_df['vector_d2v'] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>case_title</th>\n",
       "      <th>gr_no</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>vector_d2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>143051.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 507, Novembe...</td>\n",
       "      <td>IN THE MATTER OF THE PETITION OF A. O. BROOKS ...</td>\n",
       "      <td>G.R. No. 507</td>\n",
       "      <td>1901-11-05</td>\n",
       "      <td>Remedial Law</td>\n",
       "      <td>1901</td>\n",
       "      <td>[it, established, fact, brooks, obtained, abso...</td>\n",
       "      <td>[it, establish, fact, brook, obtain, absolut, ...</td>\n",
       "      <td>[0.0041221147, 0.00030034626, -0.009949138, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>143062.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 448, Septemb...</td>\n",
       "      <td>THE UNITED STATES, COMPLAINANT AND APPELLEE, V...</td>\n",
       "      <td>G.R. No. 448</td>\n",
       "      <td>1901-09-20</td>\n",
       "      <td>Criminal Law</td>\n",
       "      <td>1901</td>\n",
       "      <td>[the, offense, charged, complaint, punishable,...</td>\n",
       "      <td>[the, offens, charg, complaint, punish, penal,...</td>\n",
       "      <td>[-0.0028990796, 0.00927604, 0.003277776, 0.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>143169.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 448, Septemb...</td>\n",
       "      <td>THE UNITED STATES, COMPLAINANT AND APPELLEE, V...</td>\n",
       "      <td>G.R. No. 448</td>\n",
       "      <td>1902-09-20</td>\n",
       "      <td>Criminal Law</td>\n",
       "      <td>1902</td>\n",
       "      <td>[the, offense, charged, complaint, punishable,...</td>\n",
       "      <td>[the, offens, charg, complaint, punish, penal,...</td>\n",
       "      <td>[0.0034304094, 0.0037076662, 0.0009457428, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>143252.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 911, March 1...</td>\n",
       "      <td>MAXIMO CORTES, PLAINTIFF AND APPELLANT, VS.  J...</td>\n",
       "      <td>G.R. No. 911</td>\n",
       "      <td>1903-03-12</td>\n",
       "      <td>Civil Law</td>\n",
       "      <td>1903</td>\n",
       "      <td>[this, suit, brought, obtain, injunction, acco...</td>\n",
       "      <td>[thi, suit, brought, obtain, injunct, accord, ...</td>\n",
       "      <td>[-0.008524174, 0.00065538724, -0.0066927285, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>143269.0</td>\n",
       "      <td>&lt;center&gt;\\n&lt;h2&gt;&lt;/h2&gt;\\n&lt;h2&gt;G.R. No. 1011, May 13...</td>\n",
       "      <td>JOSE MACHUCA, PLAINTIFF AND APPELLEE, VS. CHUI...</td>\n",
       "      <td>G.R. No. 1011</td>\n",
       "      <td>1903-05-13</td>\n",
       "      <td>Civil Law</td>\n",
       "      <td>1903</td>\n",
       "      <td>[most, allegations, complaint, admitted, defen...</td>\n",
       "      <td>[most, alleg, complaint, admit, defend, hear, ...</td>\n",
       "      <td>[-0.008267059, -0.008490125, 0.0056070876, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            content  \\\n",
       "8    143051.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 507, Novembe...   \n",
       "19   143062.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 448, Septemb...   \n",
       "126  143169.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 448, Septemb...   \n",
       "209  143252.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 911, March 1...   \n",
       "226  143269.0  <center>\\n<h2></h2>\\n<h2>G.R. No. 1011, May 13...   \n",
       "\n",
       "                                            case_title          gr_no  \\\n",
       "8    IN THE MATTER OF THE PETITION OF A. O. BROOKS ...   G.R. No. 507   \n",
       "19   THE UNITED STATES, COMPLAINANT AND APPELLEE, V...   G.R. No. 448   \n",
       "126  THE UNITED STATES, COMPLAINANT AND APPELLEE, V...   G.R. No. 448   \n",
       "209  MAXIMO CORTES, PLAINTIFF AND APPELLANT, VS.  J...   G.R. No. 911   \n",
       "226  JOSE MACHUCA, PLAINTIFF AND APPELLEE, VS. CHUI...  G.R. No. 1011   \n",
       "\n",
       "    decision_date         label  year  \\\n",
       "8      1901-11-05  Remedial Law  1901   \n",
       "19     1901-09-20  Criminal Law  1901   \n",
       "126    1902-09-20  Criminal Law  1902   \n",
       "209    1903-03-12     Civil Law  1903   \n",
       "226    1903-05-13     Civil Law  1903   \n",
       "\n",
       "                                         content_clean  \\\n",
       "8    [it, established, fact, brooks, obtained, abso...   \n",
       "19   [the, offense, charged, complaint, punishable,...   \n",
       "126  [the, offense, charged, complaint, punishable,...   \n",
       "209  [this, suit, brought, obtain, injunction, acco...   \n",
       "226  [most, allegations, complaint, admitted, defen...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "8    [it, establish, fact, brook, obtain, absolut, ...   \n",
       "19   [the, offens, charg, complaint, punish, penal,...   \n",
       "126  [the, offens, charg, complaint, punish, penal,...   \n",
       "209  [thi, suit, brought, obtain, injunct, accord, ...   \n",
       "226  [most, alleg, complaint, admit, defend, hear, ...   \n",
       "\n",
       "                                            vector_d2v  \n",
       "8    [0.0041221147, 0.00030034626, -0.009949138, 0....  \n",
       "19   [-0.0028990796, 0.00927604, 0.003277776, 0.007...  \n",
       "126  [0.0034304094, 0.0037076662, 0.0009457428, -0....  \n",
       "209  [-0.008524174, 0.00065538724, -0.0066927285, -...  \n",
       "226  [-0.008267059, -0.008490125, 0.0056070876, -0....  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_pickle('content_d2v_v2.0.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('content_d2v_v2.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(col):\n",
    "    li = []\n",
    "    for i in col:\n",
    "        li.append(i.reshape(1, -1))\n",
    "    return np.concatenate(li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = train_df['vector_d2v']\n",
    "X = get_X(X_sub)\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            Civil Law       0.97      0.22      0.36       700\n",
      "       Commercial Law       0.00      0.00      0.00         0\n",
      "         Criminal Law       0.00      0.00      0.00         1\n",
      "                Labor       0.00      0.00      0.00         6\n",
      "         Legal Method       0.00      0.00      0.00         0\n",
      "Medical Jurisprudence       0.00      0.00      0.00         0\n",
      "        Political Law       0.01      0.17      0.02         6\n",
      "         Remedial Law       0.01      0.25      0.02         4\n",
      "             Taxation       0.00      0.00      0.00         0\n",
      "       Transportation       0.00      0.00      0.00         0\n",
      "\n",
      "             accuracy                           0.22       717\n",
      "            macro avg       0.10      0.06      0.04       717\n",
      "         weighted avg       0.95      0.22      0.35       717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_svm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2203626220362622\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=50, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            Civil Law       0.82      0.22      0.34       611\n",
      "       Commercial Law       0.01      0.14      0.02         7\n",
      "         Criminal Law       0.00      0.00      0.00         9\n",
      "                Labor       0.05      0.14      0.07        29\n",
      "         Legal Method       0.00      0.00      0.00         0\n",
      "Medical Jurisprudence       0.00      0.00      0.00         0\n",
      "        Political Law       0.03      0.09      0.05        34\n",
      "         Remedial Law       0.01      0.04      0.01        27\n",
      "             Taxation       0.00      0.00      0.00         0\n",
      "       Transportation       0.00      0.00      0.00         0\n",
      "\n",
      "             accuracy                           0.20       717\n",
      "            macro avg       0.09      0.06      0.05       717\n",
      "         weighted avg       0.70      0.20      0.30       717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19665271966527198\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
