{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from multiprocessing import cpu_count, Pool #for multiprocessing data\n",
    "cores = cpu_count()\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument #for doc2vec modelling\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bonding, grief, family, urban, poor, communit...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[general, santos, city, number, drug, suspect,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[brig, gen, debold, sinas, director, national,...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[politics, eyed, police, say, politics, may, b...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[general, santos, city, president, rodrigo, du...</td>\n",
       "      <td>ejks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized label\n",
       "0  [bonding, grief, family, urban, poor, communit...  ejks\n",
       "1  [general, santos, city, number, drug, suspect,...  ejks\n",
       "2  [brig, gen, debold, sinas, director, national,...  ejks\n",
       "3  [politics, eyed, police, say, politics, may, b...  ejks\n",
       "4  [general, santos, city, president, rodrigo, du...  ejks"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./Cleaned/ejks_cleaned.pkl')[['lemmatized', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[eastern, samar, gone, really, dont, know, sta...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[market, stall, product, damaged, washed, debr...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[knew, super, typhoon, strength, really, took,...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[compared, wind, rain, strong, staed, whistle,...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[thought, prepared, used, typhoon, know, feel,...</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized     label\n",
       "0  [eastern, samar, gone, really, dont, know, sta...  disaster\n",
       "1  [market, stall, product, damaged, washed, debr...  disaster\n",
       "2  [knew, super, typhoon, strength, really, took,...  disaster\n",
       "3  [compared, wind, rain, strong, staed, whistle,...  disaster\n",
       "4  [thought, prepared, used, typhoon, know, feel,...  disaster"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_pickle('./Cleaned/disaster_cleaned.pkl')[['lemmatized', 'label']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = df.append(df1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ejks        371\n",
       "disaster    122\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = main[main.label == 'ejks']\n",
    "df_minority = main[main.label == 'disaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=371,    # to match majority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging docs...\n",
      "Docs tagged.\n",
      "Training start.\n",
      "Initializing Model...\n",
      "Model Initalized. Training...\n",
      "Training complete.\n",
      "Saving model...\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "print('Tagging docs...')\n",
    "docs = [x for x in main['lemmatized'].values]\n",
    "# docs = [x for x in main_df['content_clean'].values]\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs)]\n",
    "print('Docs tagged.')\n",
    "# tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "print('Training start.')\n",
    "# epoch_logger = EpochLogger()\n",
    "epochs = 50\n",
    "vec_size = 50\n",
    "alpha = 0.025\n",
    "\n",
    "print('Initializing Model...')\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=2,\n",
    "                workers = cores,\n",
    "                dm = 1, epochs = epochs)\n",
    "#                 callbacks=[epoch_logger])\n",
    "                \n",
    "\n",
    "print('Model Initalized. Training...')\n",
    "model.build_vocab(documents = documents, progress_per=1)\n",
    "print('Training complete.')\n",
    "\n",
    "print('Saving model...')\n",
    "model.save(\"models/doc2vec.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [model.docvecs[i] for i in range(len(main))]\n",
    "main['vector_d2v'] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label</th>\n",
       "      <th>vector_d2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[bonding, grief, family, urban, poor, communit...</td>\n",
       "      <td>ejks</td>\n",
       "      <td>[0.008891293, -0.0074158455, 0.0037703046, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[general, santos, city, number, drug, suspect,...</td>\n",
       "      <td>ejks</td>\n",
       "      <td>[0.00690979, -0.0047741365, 0.0017735371, -6.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[brig, gen, debold, sinas, director, national,...</td>\n",
       "      <td>ejks</td>\n",
       "      <td>[0.007832452, -0.002955307, 0.0013261527, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[politics, eyed, police, say, politics, may, b...</td>\n",
       "      <td>ejks</td>\n",
       "      <td>[0.007552774, -0.0032720529, 0.002190555, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[general, santos, city, president, rodrigo, du...</td>\n",
       "      <td>ejks</td>\n",
       "      <td>[-0.0059859795, -0.004373776, 0.002142897, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized label  \\\n",
       "0  [bonding, grief, family, urban, poor, communit...  ejks   \n",
       "1  [general, santos, city, number, drug, suspect,...  ejks   \n",
       "2  [brig, gen, debold, sinas, director, national,...  ejks   \n",
       "3  [politics, eyed, police, say, politics, may, b...  ejks   \n",
       "4  [general, santos, city, president, rodrigo, du...  ejks   \n",
       "\n",
       "                                          vector_d2v  \n",
       "0  [0.008891293, -0.0074158455, 0.0037703046, 0.0...  \n",
       "1  [0.00690979, -0.0047741365, 0.0017735371, -6.6...  \n",
       "2  [0.007832452, -0.002955307, 0.0013261527, -0.0...  \n",
       "3  [0.007552774, -0.0032720529, 0.002190555, 0.00...  \n",
       "4  [-0.0059859795, -0.004373776, 0.002142897, -0....  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(col):\n",
    "    li = []\n",
    "    for i in col:\n",
    "        li.append(i.reshape(1, -1))\n",
    "    return np.concatenate(li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = main['vector_d2v']\n",
    "X = get_X(X_sub)\n",
    "y = main['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    disaster       0.58      0.53      0.55        80\n",
      "        ejks       0.50      0.55      0.52        69\n",
      "\n",
      "    accuracy                           0.54       149\n",
      "   macro avg       0.54      0.54      0.54       149\n",
      "weighted avg       0.54      0.54      0.54       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_svm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5369127516778524\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=50, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    disaster       0.59      0.54      0.56        80\n",
      "        ejks       0.51      0.57      0.54        69\n",
      "\n",
      "    accuracy                           0.55       149\n",
      "   macro avg       0.55      0.55      0.55       149\n",
      "weighted avg       0.55      0.55      0.55       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5503355704697986\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
